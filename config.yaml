# Discord settings:

bot_token: $KNOWLEDGE_BOT_DISCORD_TOKEN
client_id: $KNOWLEDGE_BOT_CLIENT_ID
status_message: "Dog Years DAO Assistant"

max_text: 100000
max_images: 1
max_messages: 25

use_plain_responses: true
allow_dms: true


debug_prompt: false
test_echo_mode: false
disable_safety: true

gdocs:
  enabled: false
  credentials:
    type: service_account
    project_id: $GOOGLE_PROJECT_ID
    private_key_id: $GOOGLE_PRIVATE_KEY_ID
    private_key: $GOOGLE_PRIVATE_KEY
    client_email: $GOOGLE_CLIENT_EMAIL
    client_id: $GOOGLE_CLIENT_ID
    auth_uri: $GOOGLE_AUTH_URI
    token_uri: $GOOGLE_TOKEN_URI
    auth_provider_x509_cert_url: $GOOGLE_AUTH_PROVIDER_X509_CERT_URL
    client_x509_cert_url: $GOOGLE_CLIENT_X509_CERT_URL
    universe_domain: googleapis.com
  google_application_credentials:
  folder_id: $GOOGLE_FOLDER_ID     # The Google Drive folder to sync (shared with your service account)
  sync_interval_minutes: 360
  cache_dir: "gdocs_cache"
  max_files: 1000                      # guardrails
  export_mime: "text/markdown"         # fallback to text/plain if markdown not supported


permissions:
  users:
    admin_ids: []
    allowed_ids: []
    blocked_ids: []
  roles:
    allowed_ids: []
    blocked_ids: []
  channels:
    allowed_ids: []
    blocked_ids: []


# LLM settings:

providers:
  # Remote providers:
  anthropic:
    base_url: https://api.anthropic.com/v1
    api_key: $ANTHROPIC_API_KEY
  google:
    base_url: https://generativelanguage.googleapis.com/v1beta/openai
    api_key: $GEMINI_API_KEY
  groq:
    base_url: https://api.groq.com/openai/v1
    api_key: 
  mistral:
    base_url: https://api.mistral.ai/v1
    api_key: 
  openai:
    base_url: https://api.openai.com/v1
    api_key: 
  openrouter:
    base_url: https://openrouter.ai/api/v1
    api_key: $OPENROUTER_API_KEY
  x-ai:
    base_url: https://api.x.ai/v1
    api_key: 

  # Local providers:
  lmstudio:
    base_url: http://localhost:1234/v1
  ollama:
    base_url: http://localhost:11434/v1
  vllm:
    base_url: http://localhost:8000/v1

# =============================================================================
# PRIMARY PROVIDER CONFIGURATION
# =============================================================================
# The SINGLE, UNAMBIGUOUS setting for which LLM provider to use:
primary_provider: openrouter  # ‚Üê THIS IS THE ONLY PROVIDER THAT MATTERS

# Model for the primary provider:
primary_model: openai/gpt-oss-120b

# Optional fallback models (only used if primary fails):
fallback_models:
  - provider: openai
    model: gpt-4o-mini
  - provider: google
    model: gemini-2.5-flash

# =============================================================================
# OLD MODEL LIST (DEPRECATED - kept for compatibility)
# =============================================================================

models:
  - provider: openrouter
    model: openai/gpt-oss-120b
  - provider: openai
    model: gpt-4o-mini
    name: "OpenAI GPT-4o Mini"
  - provider: google
    model: gemini-2.5-flash
    name: "Google Gemini 2.5 Flash"
  - provider: google
    model: gemini-2.5-pro
    name: "Google Gemini 2.5 Pro"
    reasoning_effort: high
  - provider: anthropic
    model: claude-3-5-sonnet-20241022
    name: "Anthropic Claude 3.5 Sonnet"


system_prompt: $SYSTEM_PROMPT_DAOCORD     # Fallback system prompt via env var (optional)